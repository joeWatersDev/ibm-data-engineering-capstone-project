# PostgreSQL Data Warehouse

You are a data engineer hired by an ecommerce company named SoftCart.com . The company retails download only items like E-Books, Movies, Songs etc. The company has international presence and customers from all over the world. The company would like to create a data warehouse so that it can create reports like
- total sales per year per country
- total sales per month per category
- total sales per quarter per country
- total sales per category per country

In part 1 you will use your data warehousing skills to design and implement a data warehouse for the company.

In part 2 you will generate reports out of the data in the data warehouse.

# Part 1 - Design a Data Warehouse

**Objectives**
- Design a Data Warehouse using the pgAdmin ERD design tool
- Create the schema in the Data Warehouse

**Tools / Software Used**
- ERD Design Tool of pgAdmin

## 1 - Design the schema
The following sample data for the warehouse is provided.

![Sample data to populate data warehouse](https://github.com/joeWatersDev/ibm-data-engineering-capstone-project/blob/main/3%20-%20PostgreSQL%20Data%20Warehouse/sampleData.png)

The company is looking at a granularity of a day. Which means they would like to have the ability to generate the report on yearly, monthly, daily, and weekday basis.

With that knowledge, we use pgAdmin's ERD design tool to design a star schema database, with a central fact table for individual orders. Dimension tables will be created to store descriptive data for each order. These will be linked to the fact table in a one-to-many relationship.

![ERD schema design](https://github.com/joeWatersDev/ibm-data-engineering-capstone-project/blob/main/3%20-%20PostgreSQL%20Data%20Warehouse/softcartRelationships.PNG)


## 2 - Export schema SQL
Use the pgAdmin ERD tool to generate the SQL to create our database.
```
-- This script was generated by a beta version of the ERD tool in pgAdmin 4.
-- Please log an issue at https://redmine.postgresql.org/projects/pgadmin4/issues/new if you find any bugs, including reproduction steps.
BEGIN;


CREATE TABLE public."softcartDimDate"
(
    dateid integer NOT NULL,
    month integer NOT NULL,
    monthname character varying(9) NOT NULL,
    day integer NOT NULL,
    weekday integer NOT NULL,
    dayname character varying(9) NOT NULL,
    year integer NOT NULL,
    PRIMARY KEY (dateid)
);

CREATE TABLE public."softcartDimCategory"
(
    categoryid integer NOT NULL,
    category character varying(30) NOT NULL,
    PRIMARY KEY (categoryid)
);

CREATE TABLE public."softcartFactSales"
(
    orderid integer NOT NULL,
    dateid integer NOT NULL,
    countryid integer NOT NULL,
    categoryid integer NOT NULL,
    itemid integer NOT NULL,
    PRIMARY KEY (orderid)
);

CREATE TABLE public."softcartDimCountry"
(
    countryid integer NOT NULL,
    country character varying(30) NOT NULL,
    PRIMARY KEY (countryid)
);

CREATE TABLE public."softcartDimItem"
(
    itemid integer NOT NULL,
    item character(30) NOT NULL,
    price numeric(2) NOT NULL,
    PRIMARY KEY (itemid)
);

ALTER TABLE public."softcartFactSales"
    ADD FOREIGN KEY (countryid)
    REFERENCES public."softcartDimCountry" (countryid)
    NOT VALID;


ALTER TABLE public."softcartFactSales"
    ADD FOREIGN KEY (categoryid)
    REFERENCES public."softcartDimCategory" (categoryid)
    NOT VALID;


ALTER TABLE public."softcartFactSales"
    ADD FOREIGN KEY (dateid)
    REFERENCES public."softcartDimDate" (dateid)
    NOT VALID;


ALTER TABLE public."softcartFactSales"
    ADD FOREIGN KEY (itemid)
    REFERENCES public."softcartDimItem" (itemid)
    NOT VALID;

END;

```


# Part 2 - Query a Data Warehouse

The schema design from above has been slightly modified by a senior engineer to better account for some expected use cases. We are tasked with loading data into the new schema, and performing queries on the data.

**Objectives**
- Load data into Data Warehouse
- Write aggregation queries
- Create MQTs


**Tools / Software Used**
- PostgreSQL Database Server

## 1 - Load data
Load the data provided into the fact and dimension tables created in part 1.

Below are the first five rows of data for each table.

DimCategory:

![Populated DimCategory table](https://github.com/joeWatersDev/ibm-data-engineering-capstone-project/blob/main/3%20-%20PostgreSQL%20Data%20Warehouse/DimCategory.PNG)

DimCountry:

![Populated DimCountry table](https://github.com/joeWatersDev/ibm-data-engineering-capstone-project/blob/main/3%20-%20PostgreSQL%20Data%20Warehouse/DimCountry.PNG)

DimDate:

![Populated DimDate table](https://github.com/joeWatersDev/ibm-data-engineering-capstone-project/blob/main/3%20-%20PostgreSQL%20Data%20Warehouse/DimDate.PNG)

FactSales:

![Populated FactSales table](https://github.com/joeWatersDev/ibm-data-engineering-capstone-project/blob/main/3%20-%20PostgreSQL%20Data%20Warehouse/FactSales.PNG)


## 2 - Query the data warehouse
We can now perform queries on our loaded data.

First, a **grouping sets** query using the columns country, category, totalsales.
```
SELECT country,category,sum(amount) as totalsales
FROM "FactSales" as sales	
LEFT JOIN "DimCategory" as category ON category.categoryid = sales.categoryid
LEFT JOIN "DimCountry" as country ON country.countryid = sales.countryid
GROUP BY GROUPING SETS (category, country)
ORDER BY category,country
```

|country|category|totalsales|
|-------|--------|----------|
||Books|239357597|
||Electronics|239912568|
||Software|240289802|
||Sports|240709913|
||Toys|240736378|
|Argentina| |21755581|
|Australia| |21522004|
|Austria| |21365726|
|Azerbaijan| |21325766|
|Belgium| |21498249|

Next, a **rollup** query using the columns year, country, and totalsales.
```
SELECT year,country,sum(amount) as totalsales
FROM "FactSales" as sales	
LEFT JOIN "DimDate" as date ON date.dateid = sales.dateid
LEFT JOIN "DimCountry" as country ON country.countryid = sales.countryid
GROUP BY ROLLUP (year, country)
ORDER BY country,year
```

|year|country|totalsales|
|-------|--------|----------|
|2019|Argentina|7163167|
|2020|Argentina|7327655|
|2021|Argentina|7264759|
|2019|Australia|7259016|
|2020|Australia|6964260|
|2021|Australia|7298728|
|2019|Austria|7320233|
|2020|Austria|7071166|
|2021|Austria|6974327|
|2019|Azerbaijan|7097729|

Finally, a **cube** query using the columns year, country, and average sales.
```
SELECT year,country,avg(amount) as averagesales
FROM "FactSales" as sales	
LEFT JOIN "DimDate" as date ON date.dateid = sales.dateid
LEFT JOIN "DimCountry" as country ON country.countryid = sales.countryid
GROUP BY CUBE (year, country)
ORDER BY country,year
```

|year|country|averagesales|
|-------|--------|----------|
|2019|Argentina|4017|
|2020|Argentina|4114|
|2021|Argentina|4102|
| |Argentina|4077|
|2019|Australia|4066|
|2020|Australia|3899|
|2021|Australia|4091|
| |Australia|4019|
|2019|Austria|4078|
|2020|Austria|3943|

## 3 - Create an Materialized Query Table
As a last step, we will create a materialized view of the total sales per country, as we expect this to be data that would be queried frequently.

```
CREATE MATERIALIZED VIEW total_sales_per_country (country, total_sales) AS
(SELECT country,sum(amount) as total_sales
FROM "FactSales" as sales
LEFT JOIN "DimCountry" as country
ON sales.countryid = country.countryid
group by country);
```

In order to populate our newly created MQT, we need to run the following SQL:
```
REFRESH MATERIALIZED VIEW total_sales_per_country;
```

Here are the first ten entries in our total_sales_per_country MQT.

|country|total_sales|
|-------|-----------|
|Argentina|21755581|
|Australia|21522004|
|Austria|21365726|
|Azerbaijan|21325766|
|Belgium|21498249|
|Brazil|21350771|
|Bulgaria|21410716|
|Canada|21575438|
|Cyprus|21500526|
|Czech Republic|21334142|